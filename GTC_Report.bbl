\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{EDMM06}

\bibitem[AB09]{audibert2009minimax}
Jean-Yves Audibert and S{\'e}bastien Bubeck.
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In {\em COLT}, pages 217--226, 2009.

\bibitem[AB10]{audibert2010best}
Jean-Yves Audibert and S{\'e}bastien Bubeck.
\newblock Best arm identification in multi-armed bandits.
\newblock In {\em COLT-23th Conference on Learning Theory-2010}, pages 13--p,
  2010.

\bibitem[ACBF02]{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47(2-3):235--256, 2002.

\bibitem[AG11]{agrawal2011analysis}
Shipra Agrawal and Navin Goyal.
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock {\em arXiv preprint arXiv:1111.1797}, 2011.

\bibitem[AMS09]{audibert2009exploration}
Jean-Yves Audibert, R{\'e}mi Munos, and Csaba Szepesv{\'a}ri.
\newblock Exploration--exploitation tradeoff using variance estimates in
  multi-armed bandits.
\newblock {\em Theoretical Computer Science}, 410(19):1876--1902, 2009.

\bibitem[AO10]{auer2010ucb}
Peter Auer and Ronald Ortner.
\newblock Ucb revisited: Improved regret bounds for the stochastic multi-armed
  bandit problem.
\newblock {\em Periodica Mathematica Hungarica}, 61(1-2):55--65, 2010.

\bibitem[BCB12]{bubeck2012regret}
S{\'e}bastien Bubeck and Nicolo Cesa-Bianchi.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock {\em arXiv preprint arXiv:1204.5721}, 2012.

\bibitem[BCBL12]{bubeck2012bandits}
S{\'e}bastien Bubeck, Nicolo Cesa-Bianchi, and G{\'a}bor Lugosi.
\newblock Bandits with heavy tail.
\newblock {\em arXiv preprint arXiv:1209.1727}, 2012.

\bibitem[BJM12]{bui2012clustered}
Loc Bui, Ramesh Johari, and Shie Mannor.
\newblock Clustered bandits.
\newblock {\em arXiv preprint arXiv:1206.4169}, 2012.

\bibitem[BMS11]{bubeck2011pure}
S{\'e}bastien Bubeck, R{\'e}mi Munos, and Gilles Stoltz.
\newblock Pure exploration in finitely-armed and continuous-armed bandits.
\newblock {\em Theoretical Computer Science}, 412(19):1832--1852, 2011.

\bibitem[BT96]{bertsekas1996neuro}
Dimitri~P Bertsekas and John~N Tsitsiklis.
\newblock Neuro-dynamic programming (optimization and neural computation
  series, 3).
\newblock {\em Athena Scientific}, 7:15--23, 1996.

\bibitem[BWV13]{bubeck2013multiple}
S{\'e}bastien Bubeck, Tengyao Wang, and Nitin Viswanathan.
\newblock Multiple identifications in multi-armed bandits.
\newblock In {\em ICML (1)}, pages 258--265, 2013.

\bibitem[CBGZ13]{cesa2013gang}
Nicolo Cesa-Bianchi, Claudio Gentile, and Giovanni Zappella.
\newblock A gang of bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  737--745, 2013.

\bibitem[CGK12]{CapGarKau12}
Olivier Cappe, Aurelien Garivier, and Emilie Kaufmann.
\newblock pymabandits, 2012.
\newblock \url{http://mloss.org/software/view/415/}.

\bibitem[CLK{\etalchar{+}}14]{chen2014combinatorial}
Shouyuan Chen, Tian Lin, Irwin King, Michael~R Lyu, and Wei Chen.
\newblock Combinatorial pure exploration of multi-armed bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  379--387, 2014.

\bibitem[EDMM06]{even2006action}
Eyal Even-Dar, Shie Mannor, and Yishay Mansour.
\newblock Action elimination and stopping conditions for the multi-armed bandit
  and reinforcement learning problems.
\newblock {\em The Journal of Machine Learning Research}, 7:1079--1105, 2006.

\bibitem[GC11]{garivier2011kl}
Aur{\'e}lien Garivier and Olivier Capp{\'e}.
\newblock The kl-ucb algorithm for bounded stochastic bandits and beyond.
\newblock {\em arXiv preprint arXiv:1102.2490}, 2011.

\bibitem[GGL12]{gabillon2012best}
Victor Gabillon, Mohammad Ghavamzadeh, and Alessandro Lazaric.
\newblock Best arm identification: A unified approach to fixed budget and fixed
  confidence.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3212--3220, 2012.

\bibitem[GGLB11]{gabillon2011multi}
Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, and S{\'e}bastien
  Bubeck.
\newblock Multi-bandit best arm identification.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2222--2230, 2011.

\bibitem[GLZ14]{gentile2014online}
Claudio Gentile, Shuai Li, and Giovanni Zappella.
\newblock Online clustering of bandits.
\newblock In {\em ICML}, pages 757--765, 2014.

\bibitem[GM11]{garivier2011upper}
Aur{\'e}lien Garivier and Eric Moulines.
\newblock On upper-confidence bound policies for switching bandit problems.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  pages 174--188. Springer, 2011.

\bibitem[GMP{\etalchar{+}}15]{ghavamzadeh2015bayesian}
Mohammad Ghavamzadeh, Shie Mannor, Joelle Pineau, Aviv Tamar, et~al.
\newblock {\em Bayesian reinforcement learning: a survey}.
\newblock World Scientific, 2015.

\bibitem[HT10]{honda2010asymptotically}
Junya Honda and Akimichi Takemura.
\newblock An asymptotically optimal bandit algorithm for bounded support
  models.
\newblock In {\em COLT}, pages 67--79. Citeseer, 2010.

\bibitem[KTAS12]{kalyanakrishnan2012pac}
Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone.
\newblock Pac subset selection in stochastic multi-armed bandits.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning (ICML-12)}, pages 655--662, 2012.

\bibitem[Lat15]{lattimore2015optimally}
Tor Lattimore.
\newblock Optimally confident ucb: Improved regret for finite-armed bandits.
\newblock {\em arXiv preprint arXiv:1507.07880}, 2015.

\bibitem[LCLS10]{li2010contextual}
Lihong Li, Wei Chu, John Langford, and Robert~E Schapire.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In {\em Proceedings of the 19th international conference on World
  wide web}, pages 661--670. ACM, 2010.

\bibitem[LGC16]{locatelli2016optimal}
Andrea Locatelli, Maurilio Gutzeit, and Alexandra Carpentier.
\newblock An optimal algorithm for the thresholding bandit problem.
\newblock {\em arXiv preprint arXiv:1605.08671}, 2016.

\bibitem[LR85]{lai1985asymptotically}
Tze~Leung Lai and Herbert Robbins.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock {\em Advances in applied mathematics}, 6(1):4--22, 1985.

\bibitem[LT16]{liu2016modification}
Yun-Ching Liu and Yoshimasa Tsuruoka.
\newblock Modification of improved upper confidence bounds for regulating
  exploration in monte-carlo tree search.
\newblock {\em Theoretical Computer Science}, 2016.

\bibitem[NL14]{nguyen2014dynamic}
Trong~T Nguyen and Hady~W Lauw.
\newblock Dynamic clustering of contextual multi-armed bandits.
\newblock In {\em Proceedings of the 23rd ACM International Conference on
  Conference on Information and Knowledge Management}, pages 1959--1962. ACM,
  2014.

\bibitem[Rob52]{robbins1952some}
Herbert Robbins.
\newblock Some aspects of the sequential design of experiments.
\newblock In {\em Herbert Robbins Selected Papers}, pages 169--177. Springer,
  1952.

\bibitem[SB98]{sutton1998reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 1998.

\bibitem[Tho33]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, pages 285--294, 1933.

\end{thebibliography}
